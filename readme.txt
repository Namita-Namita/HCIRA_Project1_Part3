Human-Centered Input Recognition Algorithms - Project 1 Part 2

###Group members:-
- Namita Namita (48479313)
- Harshwardhan Chauhan (42046851)

##System:-
The application was developed using Java. Implementation was carried out in Microsoft Visual Studio Code, a straightforward yet effective solution that provides all the IDE features required by our team for this specific project.


###Steps to install and execute the project:-
- Unzip the Project1_Part2.zip file.
- Open the Project1_Part2 folder in VS code by navigating to the editor.
- Click the UiFrame.java file to open the source code in the editor.
- Run the UiFrame.java file by clicking the run button in the right corner of the VS Code.
- The canvas along with the clear button will appear as expected.
- Try out gestures by dragging the mouse in the canvas, $1 recognizer algorithm will detect the gesture and give back the match along with the score.

###Functionality implemented:-
- We have implemented $1 Recognizer by referring to the work done by Wobbrock, Wilson, and Li.
- In part 2 of project 1, we have implemented the Live version of the $1 recognizer.
- As part of this submission, the user can use the mouse and click anywhere in the canvas, and the system will detect the mouse click and start drawing accordingly as the mouse is dragged by the user.
- The $1 Recognizer algorithm will be initiated to detect the gesture drawn as soon as the mouse is released by the user.
- After the $1 Recognizer algorithm will finish its computation, the system will display the figure name as well as the score that it computed on the top of the canvas.
- The user can then use the "Clear" button to clear the screen and re-draw any other gesture.

###Goals achieved:
a)Store the points generated by the mouse or touch events on your canvas:
- The points are stored in the "UiFrame.java" file at line number 77 and 95 in the variable "points" ArrayList.
- The ArrayList data structure will store the points as and when the mouse touches the screen and the points are generated based on the speed of the drag done by the mouse.

b)Store a default set of templates to compare new candidate (input) gestures to:
- The default set of 16 templates is stored in the "UniStroke.java" file in the variables "point0, point1....,point15" which are an array of objects of class Point.
- Line number 13 to 271 shows the implementation.
- The templates are then processed with $1 Recognizer to get the unified points of templates to compare with the user-drawn gestures at line 291.
- The AddTemplate() method will process these existing template points for comparison.

	// zigzag template
    	Point[] point6 = { new Point(307, 216), new Point(333, 186), new Point(356, 215), new Point(375, 186), new Point(399, 216), new Point(418, 186) };
    	AddTemplate("zigzag", point6);

c)implement the $1 recognition algorithm and call it when a gesture is drawn:
- The $1 recognition algorithm is implemented in the "DollarOneRecognizer.java" and "PointProcessor.java" files.

## Resample
- Resample code is present in the "PointProcessor.java" file at line 8.
- The resample() method will resample the X and Y points from the original count to a total of equally spaced 64 points.

## Rotate
- Rotate code is present in the "PointProcessor.java" file at line 92.
- The rotateBy() method will rotate the resampled gesture to a certain angle with the help of the centroid of the figure with respect to the first point.

## Scale
- Scale is present in the "PointProcessor.java" file at line 43.
- The scale() method will create a bounding box around the resampled and rotated gesture and then scale it to fill the box.

## Translate
- Translate code is present in the "PointProcessor.java" file at line 53.
- The translate() method will move the gesture to an origin with respect to the centroid of the gesture.

## Matching	
- Matching code is present in the "DollarOneRecognizer.java" file at line 22.
- The recognize() method will compare the resampled, rotated, scaled, and translated gesture to the already processed and saved templates.
- The matched gesture template as well as its score is returned for output. 


d)output the result of the recognition call to the GUI onscreen:
- The result is displayed in the title of the frame and the code is present in the file "UiFrame.java" at line 168.
	
		// Set the title to the match found and the score calculated.
        	this.setTitle("Result: "+templateName+" ("+score+") in "+(endTime-startTime)+"ms");
